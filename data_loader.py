# data_loader.py
"""
–ú–û–î–£–õ–¨: data_loader.py
======================
–ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è:
------------
- –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î Google Speech Commands Dataset (—á–µ—Ä–µ–∑ torchaudio)
- –†–æ–∑–¥—ñ–ª—è—î –¥–∞–Ω—ñ –Ω–∞ train/test
- –ó–∞—Å—Ç–æ—Å–æ–≤—É—î –ø–æ–ø–µ—Ä–µ–¥–Ω—é –æ–±—Ä–æ–±–∫—É: –ø–µ—Ä–µ—Ç–≤–æ—Ä—é—î –∞—É–¥—ñ–æ —É –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º—É
- –ü–æ–≤–µ—Ä—Ç–∞—î –æ–±‚Äô—î–∫—Ç–∏ DataLoader –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è —Ç–∞ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
"""

import torch                            # –†–æ–±–æ—Ç–∞ –∑ —Ç–µ–Ω–∑–æ—Ä–∞–º–∏ —Ç–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂–∞–º–∏
import torchaudio                       # –ë—ñ–±–ª—ñ–æ—Ç–µ–∫–∞ –¥–ª—è —Ä–æ–±–æ—Ç–∏ –∑ –∞—É–¥—ñ–æ
from torch.utils.data import random_split, DataLoader  # –Ü–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –¥–ª—è –ø–æ–¥—ñ–ª—É —Ç–∞ –ø–∞–∫–µ—Ç–Ω–æ—ó –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–∏—Ö
from torchaudio.transforms import MelSpectrogram, AmplitudeToDB  # –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –∞—É–¥—ñ–æ —É —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º—É


# === 1. –ö–ª–∞—Å –æ–±–≥–æ—Ä—Ç–∫–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç—É –∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—î—é ===
class SpeechCommandsDataset(torch.utils.data.Dataset):   # –ö–ª–∞—Å, —â–æ –¥–æ–∑–≤–æ–ª—è—î –∑–∞—Å—Ç–æ—Å—É–≤–∞—Ç–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—é –¥–æ –∫–æ–∂–Ω–æ–≥–æ –µ–ª–µ–º–µ–Ω—Ç–∞
    def __init__(self, dataset, transform=None):         # –ü—Ä–∏–π–º–∞—î –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç —ñ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—é
        self.dataset = dataset                           # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –±–∞–∑–æ–≤–∏–π –¥–∞—Ç–∞—Å–µ—Ç
        self.transform = transform                       # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—é (–º–æ–∂–µ –±—É—Ç–∏ None)

    def __len__(self):                                   # –ü–æ–≤–µ—Ä—Ç–∞—î –∫—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ —É –¥–∞—Ç–∞—Å–µ—Ç—ñ
        return len(self.dataset)

    def __getitem__(self, idx):                          # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –æ–¥–Ω–æ–≥–æ –µ–ª–µ–º–µ–Ω—Ç—É –∑–∞ —ñ–Ω–¥–µ–∫—Å–æ–º
        waveform, sample_rate, label, *_ = self.dataset[idx]  # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –∞—É–¥—ñ–æ, —á–∞—Å—Ç–æ—Ç—É –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü—ñ—ó —Ç–∞ –º—ñ—Ç–∫—É

        if self.transform:                               # –Ø–∫—â–æ –∑–∞–¥–∞–Ω–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è
            waveform = self.transform(waveform)          # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ waveform —É –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º—É

        # === –í–∏—Ä—ñ–≤–Ω—é—î–º–æ –¥–æ–≤–∂–∏–Ω—É —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∏ ===
        max_len = 100  # –¥–æ–≤–∂–∏–Ω–∞ –ø–æ –æ—Å—ñ —á–∞—Å—É (–º–æ–∂–Ω–∞ –∑–º—ñ–Ω–∏—Ç–∏)

        if waveform.size(-1) < max_len:                   # –Ø–∫—â–æ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞ –∫–æ—Ä–æ—Ç—à–∞ –∑–∞ –ø–æ—Ç—Ä—ñ–±–Ω—É
            pad = max_len - waveform.size(-1)             # –†–∞—Ö—É—î–º–æ —Å–∫—ñ–ª—å–∫–∏ –Ω—É–ª—ñ–≤ —Ç—Ä–µ–±–∞ –¥–æ–¥–∞—Ç–∏
            waveform = torch.nn.functional.pad(waveform, (0, pad))  # –î–æ–¥–∞—î–º–æ –Ω—É–ª—å–æ–≤–∏–π –ø–∞–¥–¥—ñ–Ω–≥ —Å–ø—Ä–∞–≤–∞

        elif waveform.size(-1) > max_len:                 # –Ø–∫—â–æ —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞ –¥–æ–≤—à–∞
            waveform = waveform[:, :, :max_len] if waveform.ndim == 3 else waveform[:, :max_len]  # –û–±—Ä—ñ–∑–∞—î–º–æ

        return waveform, label                            # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –≥–æ—Ç–æ–≤—É —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º—É —ñ —Ç–µ–∫—Å—Ç–æ–≤—É –º—ñ—Ç–∫—É


# === 2. –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç—É ===
def load_data(batch_size=32):                            # –û—Å–Ω–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –ø–æ–≤–µ—Ä—Ç–∞—î –¥–≤–∞ DataLoader-–∏
    import os                                             # –Ü–º–ø–æ—Ä—Ç os (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ –≤—Å–µ—Ä–µ–¥–∏–Ω—ñ)
    os.makedirs("./data", exist_ok=True)                  # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É "data", —è–∫—â–æ —ó—ó –Ω–µ–º–∞—î

    # === –û—Ç—Ä–∏–º—É—î–º–æ –±–∞–∑–æ–≤–∏–π –¥–∞—Ç–∞—Å–µ—Ç ===
    dataset = torchaudio.datasets.SPEECHCOMMANDS(         # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É Google Speech Commands
        root="./data",                                    # –ö—É–¥–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂—É–≤–∞—Ç–∏
        download=True                                     # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏, —è–∫—â–æ –Ω–µ–º–∞
    )

    # === –û–±–º–µ–∂–∏–º–æ—Å—å –∫—ñ–ª—å–∫–æ–º–∞ –∫–ª–∞—Å–∞–º–∏ ===
    selected_labels = ["yes", "no", "up", "down"]         # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ç—ñ–ª—å–∫–∏ 4 –∫–æ–º–∞–Ω–¥–∏

    # üîπ –§—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –±–µ–∑ –ø–æ–≤–Ω–æ–≥–æ –∑—á–∏—Ç—É–≤–∞–Ω–Ω—è –∞—É–¥—ñ–æ
    all_items = []                                        # –°–ø–∏—Å–æ–∫ —à–ª—è—Ö—ñ–≤ –¥–æ –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
    for wav_path in dataset._walker:                      # –ü—Ä–æ—Ö–æ–¥–∏–º–æ –ø–æ –≤—Å—ñ—Ö —à–ª—è—Ö–∞—Ö –¥–∞—Ç–∞—Å–µ—Ç—É
        label = os.path.basename(os.path.dirname(wav_path))  # –ù–∞–∑–≤–∞ –ø–∞–ø–∫–∏ ‚Äî —Ü–µ –º—ñ—Ç–∫–∞
        if label in selected_labels:                      # –Ø–∫—â–æ –º—ñ—Ç–∫–∞ –Ω–∞–º –ø—ñ–¥—Ö–æ–¥–∏—Ç—å
            all_items.append(wav_path)                    # –î–æ–¥–∞—î–º–æ —à–ª—è—Ö —É —Å–ø–∏—Å–æ–∫

    # üîπ –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π –¥–∞—Ç–∞—Å–µ—Ç –ª–∏—à–µ –∑ –ø–æ—Ç—Ä—ñ–±–Ω–∏—Ö —Ñ–∞–π–ª—ñ–≤
    dataset._walker = all_items                           # –ü–µ—Ä–µ–∑–∞–ø–∏—Å—É—î–º–æ –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ–π —Å–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Å–µ—Ç—É

    # === –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—è –∞—É–¥—ñ–æ ‚Üí –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–∞ ===
    transform = torch.nn.Sequential(                      # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω—å
        MelSpectrogram(sample_rate=16000, n_mels=64),     # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ –∞—É–¥—ñ–æ —É –º–µ–ª-—Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º—É
        AmplitudeToDB()                                   # –ü–µ—Ä–µ–≤–æ–¥–∏–º–æ —É –¥–µ—Ü–∏–±–µ–ª–∏ (–ª–æ–≥-—à–∫–∞–ª–∞)
    )

    # === –û–±–≥–æ—Ä—Ç–∫–∞ –∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—î—é ===
    processed_dataset = SpeechCommandsDataset(dataset, transform)  # –î–∞—Ç–∞—Å–µ—Ç –∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü—ñ—î—é

    # === –ü–æ–¥—ñ–ª –Ω–∞ train/test ===
    train_size = int(0.8 * len(processed_dataset))        # 80% —É —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è
    test_size = len(processed_dataset) - train_size        # 20% —É —Ç–µ—Å—Ç
    train_dataset, test_dataset = random_split(processed_dataset, [train_size, test_size])  # –†–æ–∑–¥—ñ–ª—è—î–º–æ

    # === DataLoader-–∏ ===
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)   # –¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏–π loader
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)    # –¢–µ—Å—Ç–æ–≤–∏–π loader

    return train_loader, test_loader                      # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –¥–≤–∞ –≥–æ—Ç–æ–≤—ñ DataLoader-–∏


# === 3. –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ (—Ç—ñ–ª—å–∫–∏ —è–∫—â–æ –∑–∞–ø—É—Å–∫–∞—Ç–∏ –Ω–∞–ø—Ä—è–º—É) ===
if __name__ == "__main__":                                # –í–∏–∫–æ–Ω—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ –ø—Ä–∏ –ø—Ä—è–º–æ–º—É –∑–∞–ø—É—Å–∫—É —Ñ–∞–π–ª—É
    train_loader, test_loader = load_data()               # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ
    print("–ö—ñ–ª—å–∫—ñ—Å—Ç—å –±–∞—Ç—á—ñ–≤ –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è:", len(train_loader))  # –í–∏–≤–æ–¥–∏–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –±–∞—Ç—á—ñ–≤ train
    print("–ö—ñ–ª—å–∫—ñ—Å—Ç—å –±–∞—Ç—á—ñ–≤ –¥–ª—è —Ç–µ—Å—Ç—É:", len(test_loader))        # –í–∏–≤–æ–¥–∏–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –±–∞—Ç—á—ñ–≤ test
